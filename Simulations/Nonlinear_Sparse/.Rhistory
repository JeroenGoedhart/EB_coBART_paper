}
}
}
minima = apply(WAIC,1, function (x) minimum(x)) # WAIC minimum
EbcoBART <- c()
nrep <- length(minima)
for (i in 1:nrep){
EbcoBART[i] = PMSEstest[i,minima[i]]
#RatioPMSEtest1[i] = PMSEstest[i,minima1[i]]/PMSEstest[i,minima[i]]
}
mean(PMSEstest[,1]); mean(EbcoBART)
RatioPMSEtest <- c()
nrep <- length(minima)
for (i in 1:nrep){
RatioPMSEtest[i] = PMSEstest[i,minima[i]]/PMSEstest[i,1]
#RatioPMSEtest1[i] = PMSEstest[i,minima1[i]]/PMSEstest[i,minima[i]]
}
mean(RatioPMSEtest)
res <- cbind.data.frame("Perf" = RatioPMSEtest, "Model" = c(rep(model,500)), "Setting" = Setting)
PlotResults <- c()
PlotResults <- rbind(PlotResults,res)
#res_varsel <- c()
res_varsel <- c()
G = 5
model <- "rigid"
Setting <- "G = 5, N = 100"
for (i in 1:500) {
EstProbs[i,]<-GroupProbabilities[[i]][minima[i],]
}
EstProbs <- matrix(nrow=500, ncol = G)
for (i in 1:500) {
EstProbs[i,]<-GroupProbabilities[[i]][minima[i],]
}
names(EstProbs) = paste0("G", seq(1,G,1),sep = "")
EstProbs <- cbind.data.frame(EstProbs,"Model"=rep(model,500),"Setting" = rep(Setting,500))
View(EstProbs)
res_varsel <- rbind(res_varsel,EstProbs)
load("C:/Users/VNOB-0732/Desktop/R files/Bayesian Additive Regression Trees/Grouping Information/GroupingBART/SimulationsEBBart/Final Results/Uninformative_Friedman1_5_100_2_0.95_2_EBBart_WAIC.Rdata")
model <- "flexible"
Setting <- "G = 5, N = 100"
### results
PMSEstest = results$TestPerf
WAIC = results$WAIC
GroupProbabilities = results$GroupProbs
remove(results); gc()
minima = apply(WAIC,1, function (x) minimum(x)) # WAIC minimum
EbcoBART <- c()
nrep <- length(minima)
for (i in 1:nrep){
EbcoBART[i] = PMSEstest[i,minima[i]]
#RatioPMSEtest1[i] = PMSEstest[i,minima1[i]]/PMSEstest[i,minima[i]]
}
mean(PMSEstest[,1]); mean(EbcoBART)
RatioPMSEtest <- c()
nrep <- length(minima)
for (i in 1:nrep){
RatioPMSEtest[i] = PMSEstest[i,minima[i]]/PMSEstest[i,1]
#RatioPMSEtest1[i] = PMSEstest[i,minima1[i]]/PMSEstest[i,minima[i]]
}
length(which(RatioPMSEtest>1))
mean(RatioPMSEtest)
res <- cbind.data.frame("Perf" = RatioPMSEtest, "Model" = c(rep(model,500)), "Setting" = Setting)
#PlotResults <- c()
PlotResults <- rbind(PlotResults,res)
PlotResults$Model <- factor(PlotResults$Model, levels = c(unique(PlotResults$Model)))
PlotResults$Setting <- factor(PlotResults$Setting, levels = unique(PlotResults$Setting))
save(PlotResults, file = "PlotResults_PMSERatio_uninformative.Rdata")
bp <- ggplot(PlotResults, aes(x=Model, y=Perf, group=Model))  + coord_cartesian(ylim =  c(0.4, 1.2)) +
geom_boxplot(aes(fill=Model),fatten =1 ,outlier.shape = NA) +
#scale_y_continuous(breaks=seq(0.8,2.1,0.2)) +
theme_light() +
scale_fill_viridis(discrete = T, option = "G",begin = 0.4, end = 1)+
theme(legend.title = element_blank()) + labs(x="",y="PMSE Ratio") +
geom_hline(yintercept=1,linetype=2,linewidth=1)
bp
bp <- ggplot(PlotResults, aes(x=Model, y=Perf, group=Model))  + coord_cartesian(ylim =  c(0.9, 1.1)) +
geom_boxplot(aes(fill=Model),fatten =1 ,outlier.shape = NA) +
#scale_y_continuous(breaks=seq(0.8,2.1,0.2)) +
theme_light() +
scale_fill_viridis(discrete = T, option = "G",begin = 0.4, end = 1)+
theme(legend.title = element_blank()) + labs(x="",y="PMSE Ratio") +
geom_hline(yintercept=1,linetype=2,linewidth=1)
bp
name <- paste("DecreasePerf_UninformativeFriedman","EBBart_WAIC.pdf", sep = "_")
pdf(name, width=5,height=2.5)
bp <- ggplot(PlotResults, aes(x=Model, y=Perf, group=Model))  + coord_cartesian(ylim =  c(0.9, 1.1)) +
geom_boxplot(aes(fill=Model),fatten =1 ,outlier.shape = NA) +
#scale_y_continuous(breaks=seq(0.8,2.1,0.2)) +
theme_light() +
scale_fill_viridis(discrete = T, option = "G",begin = 0.4, end = 1)+
theme(legend.title = element_blank()) + labs(x="",y="PMSE Ratio") +
geom_hline(yintercept=1,linetype=2,linewidth=1)
bp
#bp + facet_grid(. ~ Setting)
dev.off()
getwd()
model <- "flexible"
Setting <- "G = 5, N = 100"
EstProbs <- matrix(nrow=500, ncol = G)
for (i in 1:500) {
EstProbs[i,]<-GroupProbabilities[[i]][minima[i],]
}
names(EstProbs) = paste0("G", seq(1,G,1),sep = "")
EstProbs <- cbind.data.frame(EstProbs,"Model"=rep(model,500),"Setting" = rep(Setting,500))
res_varsel <- rbind(res_varsel,EstProbs)
res_varsel$Model<- factor(res_varsel$Model, levels = unique(res_varsel$Model))
res_varsel$Setting<- factor(res_varsel$Setting, levels = unique(res_varsel$Setting))
G=5
library(tidyr)
library(dplyr)
library(ggplot2)
library(viridis)
name <- c()
for (i in 1:G) {
name[i] <- as.character(i)
}
name <- append(name,c("Model","Setting"))
names(res_varsel) <- name
res_varsel1 <- pivot_longer(res_varsel, cols = c(1,2,3,4,5), names_to = "Group", values_to = "Val")
res_varsel1$Group <- factor(res_varsel1$Group, levels = unique(res_varsel1$Group))
bp <- ggplot(res_varsel1, aes(x=Group, y=Val)) +
geom_boxplot(aes(fill=Model),fatten =1, outlier.shape = NA) + #coord_cartesian(ylim =  c(0.9, 1.3)) +
#scale_y_continuous(breaks=seq(0.8,2.1,0.2)) +
theme_light() +
scale_fill_viridis(discrete = T, option = "G",begin = 0.4, end = 1)+
theme(legend.title = element_blank()) + labs(x="Group",y="Group Weights") +
geom_hline(yintercept=0.05,linetype=3,linewidth=1)
bp
bp <- ggplot(res_varsel1, aes(x=Group, y=Val)) +
geom_boxplot(aes(fill=Model),fatten =1, outlier.shape = NA) + #coord_cartesian(ylim =  c(0.9, 1.3)) +
#scale_y_continuous(breaks=seq(0.8,2.1,0.2)) +
theme_light() +
scale_fill_viridis(discrete = T, option = "G",begin = 0.4, end = 1)+
theme(legend.title = element_blank()) + labs(x="Group",y="Group Weights") +
geom_hline(yintercept=0.2,linetype=3,linewidth=1)
bp
name <- paste("GroupWeights_UinformativeFriedman_G=5","EBBart_WAIC.pdf", sep = "_")
pdf(name, width=7,height=2.5)
bp <- ggplot(res_varsel1, aes(x=Group, y=Val)) +
geom_boxplot(aes(fill=Model),fatten =1, outlier.shape = NA) + #coord_cartesian(ylim =  c(0.9, 1.3)) +
#scale_y_continuous(breaks=seq(0.8,2.1,0.2)) +
theme_light() +
scale_fill_viridis(discrete = T, option = "G",begin = 0.4, end = 1)+
theme(legend.title = element_blank()) + labs(x="Group",y="Group Weights") +
geom_hline(yintercept=0.2,linetype=3,linewidth=1)
bp
#bp + facet_grid(. ~ Setting)
dev.off()
minima
minima = apply(WAIC,1, function (x) minimum(x)) # WAIC minimum
load("C:/Users/VNOB-0732/Desktop/R files/Bayesian Additive Regression Trees/Grouping Information/GroupingBART/SimulationsEBBart/Final Results/Uninformative_Friedman1_5_100_2_0.95_2_EBBart_WAIC.Rdata")
### settings
minimum = function (x){
for (i in 1:length(x)) {
if (i==length(x)){
return(i)
}
else {
min = x[i]
if (min<x[i+1]){
return(i)
}
}
}
}
model <- "flexible"
Setting <- "G = 5, N = 100"
### results
PMSEstest = results$TestPerf
WAIC = results$WAIC
GroupProbabilities = results$GroupProbs
remove(results); gc()
minima = apply(WAIC,1, function (x) minimum(x)) # WAIC minimum
minima = apply(WAIC,1, function (x) which.min(x))
EstProbs <- matrix(nrow=500, ncol = G)
for (i in 1:500) {
EstProbs[i,]<-GroupProbabilities[[i]][minima[i],]
}
G = 5
EstProbs <- matrix(nrow=500, ncol = G)
for (i in 1:500) {
EstProbs[i,]<-GroupProbabilities[[i]][minima[i],]
}
names(EstProbs) = paste0("G", seq(1,G,1),sep = "")
EstProbs <- cbind.data.frame(EstProbs,"Model"=rep(model,500),"Setting" = rep(Setting,500))
boxplot(EstProbs)
EstProbs <- matrix(nrow=500, ncol = G)
for (i in 1:500) {
EstProbs[i,]<-GroupProbabilities[[i]][minima[i],]
}
names(EstProbs) = paste0("G", seq(1,G,1),sep = "")
boxplot(EstProbs)
View(WAIC)
minima = apply(WAIC,1, function (x) minimum(x)) # WAIC minimum
EstProbs <- matrix(nrow=500, ncol = G)
for (i in 1:500) {
EstProbs[i,]<-GroupProbabilities[[i]][minima[i],]
}
names(EstProbs) = paste0("G", seq(1,G,1),sep = "")
boxplot(EstProbs)
load("C:/Users/VNOB-0732/Desktop/R files/EB_coBART_paper/Application/DatForPaper.Rdata")
View(dat)
dat[["Xtrain"]]
dat[["Xtest"]]
dat[["CoData"]]
f <- function(x) {
10 * sin(pi * x[,1] * x[,2]) + 20 * (x[,3] - 0.5)^2 +
10 * x[,4] + 5 * x[,5]
}
set.seed(99)
sigma <- 1.0
n     <- 100
x  <- matrix(runif(n * 10), n, 10)
Ey <- f(x)
y  <- rnorm(n, Ey, sigma)
data <- data.frame(x, y)
install.packages("tgp")
####### Bayesian Cart ########
library(tgp)
?bcart
a = bcart(x,y)
a$posts
a$trees
tgp.trees(a)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
set.seed(20170823)
n_a <- 6
n_b <- 2
n_sample <- 3
sd_a <- 2
sd_b <- 1
sd_noise <- 1
dataset <- expand.grid(
B = paste0("b", seq_len(n_a * n_b)),
sample = seq_len(n_sample)
) %>%
mutate(
A = paste0("a", as.integer(B) %% n_a) %>%
factor(),
mu = rnorm(n_a, sd = sd_a)[A] + rnorm(n_a * n_b, sd = sd_b)[B],
Y = mu + rnorm(n(), sd = sd_noise)
)
View(dataset)
install.packages("lme4")
library(lme4)
model_1 <- lmer(Y ~ 0 + A + (1 | A), data = dataset)
model_1
load("C:/Users/VNOB-0732/Desktop/R files/EB_coBART_paper/Application/Cross-validated Performance/Results/CVedPerformances_lymphoma_all.Rdata")
View(results2)
results2[[1]]
results2[[2]]
res = matrix(NA, ncol=length(results2))
for (i in 1:length(results2)) {
res[,i]=results2[[i]][,1]
}
res = matrix(NA, ncol=length(results2), nrow=30)
for (i in 1:length(results2)) {
res[,i]=results2[[i]][,1]
}
names(res)=names(results2)
View(res)
names(results2)
colnames(res)=names(results2)
boxplot(res)
setwd("C:/Users/VNOB-0732/Desktop/R files/EB_coBART_paper/Simulations/Nonlinear_Sparse")
library(dbarts)
library(loo)
setwd("C:/Users/VNOB-0732/Desktop/R files/EB_coBART_paper/Simulations/Nonlinear_Sparse")
minimum = function (x){
for (i in 1:length(x)) {
if (i==length(x)){
return(i)
}
else {
min = x[i]
if (min<x[i+1]){
return(i)
}
}
}
}
library(dbarts)
library(loo)
p <- 500
sigma <- 1.0
N <- 100
G <- 5   #number of groups
GroupStructure <- c(rep(p/G,G))
g <- function(x) {
10 * sin(pi * x[,1] * x[,2]) + 20 * (x[,101] - 0.5)^2 + 10 * x[,102] + 10 * x[,3]
}
model <- "rigid"
if (model=="rigid"){k = 1; base = .1; power = 4.0}
if (model=="flexible"){k=2; base = .95; power = 2.0}
nu <- 10 ; quant <- .75 # Error variance hyperparameters
nIter <- 10
nrep <- 500
### compute est. probs for EBcoBART
load("Results/Friedman_5_100_1_0.1_4_EBBart_WAIC_Final.Rdata")
GroupProbs <- results$GroupProbs
waic <- results$WAIC
remove(results); gc()
minima = apply(waic,1, function (x) minimum(x)) # WAIC minimum
EstProbs <- matrix(nrow=500, ncol = G)
for (i in 1:500) {
EstProbs[i,]<-GroupProbs[[i]][minima[i],]
}
nrep = 500
VarCountsEBco = matrix(NA,nrow = nrep, ncol = p)
VarCountsDef = matrix(NA,nrow = nrep, ncol = p)
X <- matrix(runif(N * p), N, p)
Y <- g(X)+ rnorm(N, 0, sigma)
# hyperparameter initialization
sigest <- sd(Y)*0.667
fitDefault <- bart(x.train = X, y.train = Y, # training data
ndpost = 12000L,   # number of posterior samples
nskip = 12000L, # number of "warmup" samples to discard
nchain = 5L,   # number of independent, parallel chains
ntree = 50L,    # number of trees per chain
keeptrees = F,
verbose = F,
k = k, base = base, power = power, # hyperparameters tree
sigest = sigest,sigdf = nu, sigquant = quant,  # hyperparameters error variance
splitprobs = c()   # hyperparameter that will be updated using EB and co-data
)
VarDef <- colSums(fitDefault$varcount)
VarDef
paste0(x,seq(1,500))
paste0("x",seq(1,500))
X <- matrix(runif(N * p), N, p)
colnames(X) <- paste0("x",seq(1,500))
View(X)
Y <- g(X)+ rnorm(N, 0, sigma)
# hyperparameter initialization
sigest <- sd(Y)*0.667
fitDefault <- bart(x.train = X, y.train = Y, # training data
ndpost = 12000L,   # number of posterior samples
nskip = 12000L, # number of "warmup" samples to discard
nchain = 5L,   # number of independent, parallel chains
ntree = 50L,    # number of trees per chain
keeptrees = F,
verbose = F,
k = k, base = base, power = power, # hyperparameters tree
sigest = sigest,sigdf = nu, sigquant = quant,  # hyperparameters error variance
splitprobs = c()   # hyperparameter that will be updated using EB and co-data
)
VarDef <- colSums(fitDefault$varcount)
VarDef
sort(VarDef)
sort(VarDef,decreasing = T)
names(sort(VarDef,decreasing = T))
VarDef <- sort(colSums(fitDefault$varcount))
VarDef <- sort(colSums(fitDefault$varcount),decreasing = T)
VarDef
setwd("C:/Users/VNOB-0732/Desktop/R files/EB_coBART_paper/Simulations/Nonlinear_Sparse")
minimum = function (x){
for (i in 1:length(x)) {
if (i==length(x)){
return(i)
}
else {
min = x[i]
if (min<x[i+1]){
return(i)
}
}
}
}
library(dbarts)
library(loo)
p <- 500
sigma <- 1.0
N <- 100
G <- 5   #number of groups
GroupStructure <- c(rep(p/G,G))
g <- function(x) {
10 * sin(pi * x[,1] * x[,2]) + 20 * (x[,101] - 0.5)^2 + 10 * x[,102] + 10 * x[,3]
}
model <- "rigid"
if (model=="rigid"){k = 1; base = .1; power = 4.0}
if (model=="flexible"){k=2; base = .95; power = 2.0}
nu <- 10 ; quant <- .75 # Error variance hyperparameters
nIter <- 10
nrep <- 3
### compute est. probs for EBcoBART
load("Results/Friedman_5_100_1_0.1_4_EBBart_WAIC_Final.Rdata")
GroupProbs <- results$GroupProbs
waic <- results$WAIC
remove(results); gc()
minima = apply(waic,1, function (x) minimum(x)) # WAIC minimum
EstProbs <- matrix(nrow=500, ncol = G)
for (i in 1:500) {
EstProbs[i,]<-GroupProbs[[i]][minima[i],]
}
nrep = 500
VarCountsEBco = vector("list", length = nrep)
VarCountsDef = vector("list", length = nrep)
for (j in 1:nrep){    # for loop representing simulated data sets
print(paste("Sim","Iter",j,sep = " "))
# simulate training data, either setting 1 or setting 2
set.seed(j^3+239)
X <- matrix(runif(N * p), N, p)
colnames(X) <- paste0("x",seq(1,500))
Y <- g(X)+ rnorm(N, 0, sigma)
# hyperparameter initialization
sigest <- sd(Y)*0.667
fitDefault <- bart(x.train = X, y.train = Y, # training data
ndpost = 12000L,   # number of posterior samples
nskip = 12000L, # number of "warmup" samples to discard
nchain = 5L,   # number of independent, parallel chains
ntree = 50L,    # number of trees per chain
keeptrees = F,
verbose = F,
k = k, base = base, power = power, # hyperparameters tree
sigest = sigest,sigdf = nu, sigquant = quant,  # hyperparameters error variance
splitprobs = c()   # hyperparameter that will be updated using EB and co-data
)
VarCountsDef[[j]] <- sort(colSums(fitDefault$varcount),decreasing = T)
weights <- c()
for (i in 1:G) {
weights <- append(weights,rep(EstProbs[j,i],p/G))
}
weights
fitEBco <- bart(x.train = X, y.train = Y, # training data
ndpost = 12000L,   # number of posterior samples
nskip = 12000L, # number of "warmup" samples to discard
nchain = 5L,   # number of independent, parallel chains
ntree = 50L,    # number of trees per chain
keeptrees = F,
verbose = F,
k = k, base = base, power = power, # hyperparameters tree
sigest = sigest,sigdf = nu, sigquant = quant,  # hyperparameters error variance
splitprobs = weights   # hyperparameter that will be updated using EB and co-data
)
VarCountsEBco[[j]] <- sort(colSums(fitEBco$varcount),decreasing = T)
}
View(VarCountsEBco)
VarCountsDef[[1]];VarCountsEBco[[1]]
VarCountsEBco[[1]]
VarCountsDef[[5]];VarCountsEBco[[1]]
VarCountsDef[[5]]
VarCountsEBco[[5]]
VarCountsDef[[4]]
VarCountsEBco[[4]]
#model <- "rigid"
model <- "flexible"
if (model=="rigid"){k = 1; base = .1; power = 4.0}
if (model=="flexible"){k=2; base = .95; power = 2.0}
nu <- 10 ; quant <- .75 # Error variance hyperparameters
nIter <- 10
nrep <- 3
### compute est. probs for EBcoBART
load("Results/Friedman_5_100_2_0.95_2_EBBart_WAIC_Final.Rdata")
GroupProbs <- results$GroupProbs
waic <- results$WAIC
remove(results); gc()
minima = apply(waic,1, function (x) minimum(x)) # WAIC minimum
EstProbs <- matrix(nrow=500, ncol = G)
for (i in 1:500) {
EstProbs[i,]<-GroupProbs[[i]][minima[i],]
}
nrep = 500
VarCountsEBco = vector("list", length = nrep)
VarCountsDef = vector("list", length = nrep)
for (j in 1:nrep){    # for loop representing simulated data sets
print(paste("Sim","Iter",j,sep = " "))
# simulate training data, either setting 1 or setting 2
set.seed(j^3+239)
X <- matrix(runif(N * p), N, p)
colnames(X) <- paste0("x",seq(1,500))
Y <- g(X)+ rnorm(N, 0, sigma)
# hyperparameter initialization
sigest <- sd(Y)*0.667
fitDefault <- bart(x.train = X, y.train = Y, # training data
ndpost = 12000L,   # number of posterior samples
nskip = 12000L, # number of "warmup" samples to discard
nchain = 5L,   # number of independent, parallel chains
ntree = 50L,    # number of trees per chain
keeptrees = F,
verbose = F,
k = k, base = base, power = power, # hyperparameters tree
sigest = sigest,sigdf = nu, sigquant = quant,  # hyperparameters error variance
splitprobs = c()   # hyperparameter that will be updated using EB and co-data
)
VarCountsDef[[j]] <- sort(colSums(fitDefault$varcount),decreasing = T)
weights <- c()
for (i in 1:G) {
weights <- append(weights,rep(EstProbs[j,i],p/G))
}
weights
fitEBco <- bart(x.train = X, y.train = Y, # training data
ndpost = 12000L,   # number of posterior samples
nskip = 12000L, # number of "warmup" samples to discard
nchain = 5L,   # number of independent, parallel chains
ntree = 50L,    # number of trees per chain
keeptrees = F,
verbose = F,
k = k, base = base, power = power, # hyperparameters tree
sigest = sigest,sigdf = nu, sigquant = quant,  # hyperparameters error variance
splitprobs = weights   # hyperparameter that will be updated using EB and co-data
)
VarCountsEBco[[j]] <- sort(colSums(fitEBco$varcount),decreasing = T)
}
VarCountsDef[[3]][1:20]
VarCountsEBco[[4]][1:20]
VarCountsEBco[[3]][1:20]
VarCountsDef[[1]][1:20]
VarCountsEBco[[1]][1:20]
VarCountsDef[[2]][1:20]
VarCountsEBco[[2]][1:20]
